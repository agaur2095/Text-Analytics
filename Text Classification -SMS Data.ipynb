{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aee1d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "2d065bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with a simple example\n",
    "simple_train = ['call you tonight', 'Call me a cab', 'please call me... PLEASE!','you will be alright']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "e03c6a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call you tonight',\n",
       " 'Call me a cab',\n",
       " 'please call me... PLEASE!',\n",
       " 'you will be alright']"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "5bdb6912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn the 'vocabulary' of the training data\n",
    "vect = CountVectorizer()\n",
    "vect.fit(simple_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "7d8b4bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alright', 'be', 'cab', 'call', 'me', 'please', 'tonight', 'will', 'you']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaura\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "6150ed86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 13 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform trainig data to documant term matrix\n",
    "simple_train_dtm = vect.transform(simple_train)\n",
    "simple_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "a26f9efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alright</th>\n",
       "      <th>be</th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>will</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alright  be  cab  call  me  please  tonight  will  you\n",
       "0        0   0    0     1   0       0        1     0    1\n",
       "1        0   0    1     1   1       0        0     0    0\n",
       "2        0   0    0     1   1       2        0     0    0\n",
       "3        1   1    0     0   0       0        0     1    1"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(simple_train_dtm.todense(),columns =vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "8be07dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;background-color: white;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###TFIDF vectorizer\n",
    "tfvect=TfidfVectorizer()\n",
    "tfvect.fit(simple_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "e76cebeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaura\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['alright', 'be', 'cab', 'call', 'me', 'please', 'tonight', 'will', 'you']"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfvect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "58eb36f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_train_dtm=tfvect.transform(simple_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "6ed361fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alright</th>\n",
       "      <th>be</th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>will</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.702035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.553492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.702035</td>\n",
       "      <td>0.448100</td>\n",
       "      <td>0.553492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.284626</td>\n",
       "      <td>0.351570</td>\n",
       "      <td>0.891844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.525473</td>\n",
       "      <td>0.525473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525473</td>\n",
       "      <td>0.414289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alright        be       cab      call        me    please   tonight  \\\n",
       "0  0.000000  0.000000  0.000000  0.448100  0.000000  0.000000  0.702035   \n",
       "1  0.000000  0.000000  0.702035  0.448100  0.553492  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.284626  0.351570  0.891844  0.000000   \n",
       "3  0.525473  0.525473  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       will       you  \n",
       "0  0.000000  0.553492  \n",
       "1  0.000000  0.000000  \n",
       "2  0.000000  0.000000  \n",
       "3  0.525473  0.414289  "
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(simple_train_dtm.todense(),columns=tfvect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "00d94895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaura\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alright</th>\n",
       "      <th>be</th>\n",
       "      <th>be alright</th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>call cab</th>\n",
       "      <th>call please</th>\n",
       "      <th>call tonight</th>\n",
       "      <th>please</th>\n",
       "      <th>please call</th>\n",
       "      <th>tonight</th>\n",
       "      <th>will</th>\n",
       "      <th>will be</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.644503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.644503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.644503</td>\n",
       "      <td>0.411378</td>\n",
       "      <td>0.644503</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790112</td>\n",
       "      <td>0.395056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alright        be  be alright       cab      call  call cab  call please  \\\n",
       "0  0.000000  0.000000    0.000000  0.000000  0.411378  0.000000     0.000000   \n",
       "1  0.000000  0.000000    0.000000  0.644503  0.411378  0.644503     0.000000   \n",
       "2  0.000000  0.000000    0.000000  0.000000  0.252159  0.000000     0.395056   \n",
       "3  0.447214  0.447214    0.447214  0.000000  0.000000  0.000000     0.000000   \n",
       "\n",
       "   call tonight    please  please call   tonight      will   will be  \n",
       "0      0.644503  0.000000     0.000000  0.644503  0.000000  0.000000  \n",
       "1      0.000000  0.000000     0.000000  0.000000  0.000000  0.000000  \n",
       "2      0.000000  0.790112     0.395056  0.000000  0.000000  0.000000  \n",
       "3      0.000000  0.000000     0.000000  0.000000  0.447214  0.447214  "
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Using n gram values\n",
    "vect = TfidfVectorizer(ngram_range=(1,2), stop_words=['me','you'])\n",
    "vect.fit(simple_train)\n",
    "\n",
    "# transform training data into a 'document-term matrix'\n",
    "simple_train_dtm = vect.transform(simple_train)\n",
    "simple_train_dtm.todense()\n",
    "\n",
    "cv = pd.DataFrame(simple_train_dtm.todense())\n",
    "cv.columns = vect.get_feature_names()\n",
    "cv\n",
    "#As we can see the columns names have been sorted in the alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "4f046dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "####defining the stop words\n",
    "\n",
    "sw=['me', 'you', 'i', 'am']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "2ba9a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## UDF for the lower case conversion\n",
    "def low_case(x):\n",
    "    x=x.lower()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "c85e95eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvect = TfidfVectorizer(analyzer='word',lowercase=False, preprocessor=low_case, ngram_range=(1,1), max_features=10, max_df=3, min_df=1, stop_words=sw)\n",
    "tvect = tvect.fit(simple_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "a00792cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaura\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alright</th>\n",
       "      <th>be</th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>will</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842926</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.842926</td>\n",
       "      <td>0.538029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304035</td>\n",
       "      <td>0.952661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alright       be       cab      call    please   tonight     will\n",
       "0  0.00000  0.00000  0.000000  0.538029  0.000000  0.842926  0.00000\n",
       "1  0.00000  0.00000  0.842926  0.538029  0.000000  0.000000  0.00000\n",
       "2  0.00000  0.00000  0.000000  0.304035  0.952661  0.000000  0.00000\n",
       "3  0.57735  0.57735  0.000000  0.000000  0.000000  0.000000  0.57735"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_train_tdtm = tvect.transform(simple_train)\n",
    "pd.DataFrame(simple_train_tdtm.toarray(), columns=tvect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "a526f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Testing on the above trained vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "48e5fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"Are you alright\"]\n",
    "test_tdtm = tvect.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "af96d960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaura\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "test_dtm_df = pd.DataFrame(test_tdtm.toarray(), columns=tvect.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "85d6934e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alright</th>\n",
       "      <th>be</th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>will</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alright   be  cab  call  please  tonight  will\n",
       "0      1.0  0.0  0.0   0.0     0.0      0.0   0.0"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dtm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "47ef3229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Working on SMS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "1034ca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms = pd.read_csv('D:/Python/Dataset/sms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "8b50171e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "f2e2674e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.label.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "83ff6bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Converting Label to the numeric data\n",
    "sms['label'] = sms.label.map({'ham':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "e0e0256e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro...\n",
       "5      1  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6      0  Even my brother is not like to speak with me. ...\n",
       "7      0  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8      1  WINNER!! As a valued network customer you have...\n",
       "9      1  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "3ff8887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##defining the X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "62c246be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=sms['message']\n",
    "y=sms['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "0752c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPlitting into the train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "fd6b0692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "81fa2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VEctorizing and cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "398fe849",
   "metadata": {},
   "outputs": [],
   "source": [
    "##X_train=[\"Nah I don't think he goes to usf, he lives around here though\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "b1129cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "601b1184",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "75022aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def pre_process_text(x):\n",
    "    x = x.lower()\n",
    "    x = x.strip()\n",
    "    x = re.sub(r' +', ' ', x)\n",
    "    x = re.sub(r\"[-()\\\"#/@;:{}`+=~|.!?,'0-9]\", \"\", x)\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "f754cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(analyzer='word',lowercase=True, preprocessor=pre_process_text, ngram_range=(1,1), max_features=1000, max_df=0.95, min_df=10, stop_words=stop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "85725f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaura\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['arent', 'couldnt', 'didnt', 'doesnt', 'dont', 'hadnt', 'hasnt', 'havent', 'isnt', 'mightnt', 'mustnt', 'neednt', 'shant', 'shes', 'shouldnt', 'shouldve', 'thatll', 'wasnt', 'werent', 'wont', 'wouldnt', 'youd', 'youll', 'youre', 'youve'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4457x705 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 23266 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn training data vocabulary, then create document-term matrix\n",
    "vect = vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "ad73b281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "f93e128f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaura\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "### Feature/Token names\n",
    "X_train_tokens = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "58feb459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['able', 'abt', 'account', 'actually', 'address', 'aft', 'afternoon', 'age', 'ah', 'aight', 'almost', 'alone', 'already', 'alright', 'also', 'always', 'amp', 'ampm', 'angry', 'another', 'answer', 'anyone', 'anything', 'anytime', 'anyway', 'apply', 'ard', 'around', 'ask', 'asked', 'asking', 'ass', 'attempt', 'auction', 'available', 'await', 'award', 'awarded', 'away', 'awesome', 'babe', 'baby', 'back', 'bad', 'beautiful', 'bed', 'believe', 'best', 'better', 'big']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tokens[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "da11ecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_mat=pd.DataFrame(X_train_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "e4b15c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>abt</th>\n",
       "      <th>account</th>\n",
       "      <th>actually</th>\n",
       "      <th>address</th>\n",
       "      <th>aft</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>age</th>\n",
       "      <th>ah</th>\n",
       "      <th>aight</th>\n",
       "      <th>...</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>youll</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.322759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4457 rows × 705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      able  abt  account  actually  address  aft  afternoon       age   ah  \\\n",
       "0      0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.000000  0.0   \n",
       "1      0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.000000  0.0   \n",
       "2      0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.000000  0.0   \n",
       "3      0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.000000  0.0   \n",
       "4      0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.000000  0.0   \n",
       "...    ...  ...      ...       ...      ...  ...        ...       ...  ...   \n",
       "4452   0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.000000  0.0   \n",
       "4453   0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.000000  0.0   \n",
       "4454   0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.000000  0.0   \n",
       "4455   0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.322759  0.0   \n",
       "4456   0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.000000  0.0   \n",
       "\n",
       "      aight  ...  yes  yesterday  yet   yo  youll  youre  youve   yr  yrs  yup  \n",
       "0       0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "1       0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "2       0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "3       0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "4       0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "...     ...  ...  ...        ...  ...  ...    ...    ...    ...  ...  ...  ...  \n",
       "4452    0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "4453    0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "4454    0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "4455    0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "4456    0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "\n",
       "[4457 rows x 705 columns]"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "dc3a4fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Building and training to classify the Spam and Ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "cecc6c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;background-color: white;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a Naive Bayes model using X_train_dtm\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "nb = MultinomialNB()\n",
    "#nb = GaussianNB()\n",
    "nb.fit(doc_term_mat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "81a852e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "1652d3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaura\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MultinomialNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class_train = nb.predict(doc_term_mat)\n",
    "y_pred_class = nb.predict(X_test_dtm.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "3b02d4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9748878923766816\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "9fb243f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[966   2]\n",
      " [ 26 121]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "59ffbdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3857\n",
      "           1       0.98      0.84      0.91       600\n",
      "\n",
      "    accuracy                           0.98      4457\n",
      "   macro avg       0.98      0.92      0.95      4457\n",
      "weighted avg       0.98      0.98      0.98      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, y_pred_class_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "da5070e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       968\n",
      "           1       0.98      0.82      0.90       147\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.91      0.94      1115\n",
      "weighted avg       0.98      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b635ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d69a7be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "374b6d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sms=[\"You have won the cash prize of $100\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "54eff9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.71405698,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.70008759, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm=vect.transform(new_sms).todense()\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "a1f44985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(pd.DataFrame(dtm,columns=vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d966138e",
   "metadata": {},
   "source": [
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2976e7",
   "metadata": {},
   "source": [
    "#### Earlier we have performed the text classification without using the Lmmatization or stemming ,in this ##### part we will repeat the same steps and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47f8c417",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms = pd.read_csv('D:/Python/Dataset/sms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "077e4a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e527a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### lemmatization on the message column \n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85da09be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(x):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmatizer.lemmatize(word,pos='v') for word in word_tokenize(x)])  ### parts of speech as verb\n",
    "\n",
    "sms['msg_lemmatized'] = sms['message'].apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dcfcbafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms=sms[['label','msg_lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d92131f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point , crazy .. Available onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar ... Joking wif u oni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor ... U c already then sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I do n't think he go to usf , he live arou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                     msg_lemmatized\n",
       "0   ham  Go until jurong point , crazy .. Available onl...\n",
       "1   ham                    Ok lar ... Joking wif u oni ...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor ... U c already then sa...\n",
       "4   ham  Nah I do n't think he go to usf , he live arou..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "338390ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms['label']=sms['label'].map({'ham':0,'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b41cc584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point , crazy .. Available onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar ... Joking wif u oni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor ... U c already then sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I do n't think he go to usf , he live arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This be the 2nd time we have try 2 contact u. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>Will ü b go to esplanade fr home ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity , * be in mood for that . So ... any othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy do some bitch but I act like i 'd be i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl . Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                     msg_lemmatized\n",
       "0         0  Go until jurong point , crazy .. Available onl...\n",
       "1         0                    Ok lar ... Joking wif u oni ...\n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         0  U dun say so early hor ... U c already then sa...\n",
       "4         0  Nah I do n't think he go to usf , he live arou...\n",
       "...     ...                                                ...\n",
       "5567      1  This be the 2nd time we have try 2 contact u. ...\n",
       "5568      0                 Will ü b go to esplanade fr home ?\n",
       "5569      0  Pity , * be in mood for that . So ... any othe...\n",
       "5570      0  The guy do some bitch but I act like i 'd be i...\n",
       "5571      0                        Rofl . Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eea3b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=sms['msg_lemmatized']\n",
    "y=sms['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d526e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ce5102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef61446f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457,)\n",
      "(4457,)\n",
      "(1115,)\n",
      "(1115,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4f5e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def pre_process_text(x):\n",
    "    x = x.lower()\n",
    "    x = x.strip()\n",
    "    x = re.sub(r' +', ' ', x)\n",
    "    x= re.sub(r\"[-()\\\"#/@;:{}`+=~|.!?,'0-9]\", \"\", x)\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e87992e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "30df3e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebdd0693",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(analyzer='word',lowercase=True, preprocessor=pre_process_text, ngram_range=(1,1), max_features=1000, max_df=0.95, min_df=10, stop_words=stop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b5d4c579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4457x672 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 24179 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn training data vocabulary, then create document-term matrix\n",
    "vect = vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd39cae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4ea7bbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaura\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "### Feature Names\n",
    "X_train_tokens = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "85dbea37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able',\n",
       " 'abt',\n",
       " 'account',\n",
       " 'actually',\n",
       " 'add',\n",
       " 'address',\n",
       " 'aft',\n",
       " 'afternoon',\n",
       " 'age',\n",
       " 'ah',\n",
       " 'aight',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'always',\n",
       " 'amp',\n",
       " 'ampm',\n",
       " 'angry',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'apply',\n",
       " 'ard',\n",
       " 'around',\n",
       " 'ask',\n",
       " 'ass',\n",
       " 'attempt',\n",
       " 'auction',\n",
       " 'available',\n",
       " 'await',\n",
       " 'award',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'babe',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'bath',\n",
       " 'bcoz',\n",
       " 'beautiful',\n",
       " 'bed',\n",
       " 'believe',\n",
       " 'best',\n",
       " 'better',\n",
       " 'big',\n",
       " 'bill',\n",
       " 'birthday',\n",
       " 'bite',\n",
       " 'bonus',\n",
       " 'book',\n",
       " 'bore',\n",
       " 'bout',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boytoy',\n",
       " 'break',\n",
       " 'bring',\n",
       " 'brother',\n",
       " 'bt',\n",
       " 'bus',\n",
       " 'busy',\n",
       " 'buy',\n",
       " 'ca',\n",
       " 'call',\n",
       " 'camcorder',\n",
       " 'camera',\n",
       " 'cancel',\n",
       " 'cant',\n",
       " 'car',\n",
       " 'card',\n",
       " 'care',\n",
       " 'carlos',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'catch',\n",
       " 'cause',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'charge',\n",
       " 'chat',\n",
       " 'check',\n",
       " 'chennai',\n",
       " 'chikku',\n",
       " 'choose',\n",
       " 'claim',\n",
       " 'class',\n",
       " 'clean',\n",
       " 'close',\n",
       " 'club',\n",
       " 'code',\n",
       " 'collect',\n",
       " 'collection',\n",
       " 'college',\n",
       " 'colour',\n",
       " 'come',\n",
       " 'comin',\n",
       " 'company',\n",
       " 'complete',\n",
       " 'complimentary',\n",
       " 'computer',\n",
       " 'confirm',\n",
       " 'congrats',\n",
       " 'congratulations',\n",
       " 'contact',\n",
       " 'cool',\n",
       " 'correct',\n",
       " 'cos',\n",
       " 'cost',\n",
       " 'could',\n",
       " 'course',\n",
       " 'coz',\n",
       " 'crave',\n",
       " 'credit',\n",
       " 'cs',\n",
       " 'cum',\n",
       " 'customer',\n",
       " 'cut',\n",
       " 'da',\n",
       " 'dad',\n",
       " 'darlin',\n",
       " 'dat',\n",
       " 'date',\n",
       " 'day',\n",
       " 'days',\n",
       " 'de',\n",
       " 'deal',\n",
       " 'dear',\n",
       " 'decide',\n",
       " 'decimal',\n",
       " 'delivery',\n",
       " 'den',\n",
       " 'detail',\n",
       " 'didnt',\n",
       " 'die',\n",
       " 'difficult',\n",
       " 'dinner',\n",
       " 'dis',\n",
       " 'dont',\n",
       " 'double',\n",
       " 'download',\n",
       " 'draw',\n",
       " 'dream',\n",
       " 'drink',\n",
       " 'drive',\n",
       " 'drop',\n",
       " 'drug',\n",
       " 'dude',\n",
       " 'dun',\n",
       " 'dunno',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'either',\n",
       " 'else',\n",
       " 'email',\n",
       " 'end',\n",
       " 'enjoy',\n",
       " 'enough',\n",
       " 'enter',\n",
       " 'entry',\n",
       " 'eve',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'expires',\n",
       " 'extra',\n",
       " 'face',\n",
       " 'family',\n",
       " 'fancy',\n",
       " 'far',\n",
       " 'feel',\n",
       " 'figure',\n",
       " 'film',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'finish',\n",
       " 'first',\n",
       " 'fix',\n",
       " 'follow',\n",
       " 'fone',\n",
       " 'food',\n",
       " 'forever',\n",
       " 'forget',\n",
       " 'forward',\n",
       " 'fr',\n",
       " 'free',\n",
       " 'freemsg',\n",
       " 'fri',\n",
       " 'friday',\n",
       " 'friend',\n",
       " 'friends',\n",
       " 'friendship',\n",
       " 'frm',\n",
       " 'frnd',\n",
       " 'frnds',\n",
       " 'fuck',\n",
       " 'full',\n",
       " 'fun',\n",
       " 'game',\n",
       " 'gas',\n",
       " 'gd',\n",
       " 'get',\n",
       " 'gift',\n",
       " 'girl',\n",
       " 'girls',\n",
       " 'give',\n",
       " 'go',\n",
       " 'god',\n",
       " 'goin',\n",
       " 'going',\n",
       " 'gon',\n",
       " 'good',\n",
       " 'goodmorning',\n",
       " 'got',\n",
       " 'gr',\n",
       " 'great',\n",
       " 'grin',\n",
       " 'gt',\n",
       " 'guarantee',\n",
       " 'guaranteed',\n",
       " 'gud',\n",
       " 'guess',\n",
       " 'guy',\n",
       " 'haf',\n",
       " 'haha',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'happen',\n",
       " 'happiness',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'hav',\n",
       " 'havent',\n",
       " 'head',\n",
       " 'hear',\n",
       " 'heart',\n",
       " 'hee',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'hit',\n",
       " 'hmmm',\n",
       " 'hold',\n",
       " 'holiday',\n",
       " 'home',\n",
       " 'hop',\n",
       " 'hope',\n",
       " 'hot',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'hows',\n",
       " 'hrs',\n",
       " 'http',\n",
       " 'huh',\n",
       " 'hungry',\n",
       " 'hurt',\n",
       " 'id',\n",
       " 'identifier',\n",
       " 'ill',\n",
       " 'im',\n",
       " 'important',\n",
       " 'india',\n",
       " 'info',\n",
       " 'information',\n",
       " 'interest',\n",
       " 'invite',\n",
       " 'ipod',\n",
       " 'job',\n",
       " 'join',\n",
       " 'joke',\n",
       " 'jus',\n",
       " 'juz',\n",
       " 'keep',\n",
       " 'kind',\n",
       " 'kiss',\n",
       " 'know',\n",
       " 'knw',\n",
       " 'land',\n",
       " 'landline',\n",
       " 'laptop',\n",
       " 'lar',\n",
       " 'last',\n",
       " 'late',\n",
       " 'later',\n",
       " 'latest',\n",
       " 'least',\n",
       " 'leave',\n",
       " 'leh',\n",
       " 'lei',\n",
       " 'lesson',\n",
       " 'let',\n",
       " 'liao',\n",
       " 'life',\n",
       " 'light',\n",
       " 'like',\n",
       " 'line',\n",
       " 'link',\n",
       " 'listen',\n",
       " 'little',\n",
       " 'live',\n",
       " 'load',\n",
       " 'loan',\n",
       " 'log',\n",
       " 'lol',\n",
       " 'long',\n",
       " 'look',\n",
       " 'lor',\n",
       " 'lose',\n",
       " 'lot',\n",
       " 'lovable',\n",
       " 'love',\n",
       " 'lovely',\n",
       " 'lt',\n",
       " 'ltd',\n",
       " 'luck',\n",
       " 'lucky',\n",
       " 'lunch',\n",
       " 'luv',\n",
       " 'mah',\n",
       " 'mail',\n",
       " 'make',\n",
       " 'man',\n",
       " 'many',\n",
       " 'mat',\n",
       " 'match',\n",
       " 'mate',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'mean',\n",
       " 'meet',\n",
       " 'message',\n",
       " 'might',\n",
       " 'min',\n",
       " 'mind',\n",
       " 'mine',\n",
       " 'mins',\n",
       " 'minute',\n",
       " 'minutes',\n",
       " 'miss',\n",
       " 'mob',\n",
       " 'mobile',\n",
       " 'mobileupd',\n",
       " 'mom',\n",
       " 'money',\n",
       " 'month',\n",
       " 'months',\n",
       " 'morning',\n",
       " 'motorola',\n",
       " 'move',\n",
       " 'movie',\n",
       " 'mrng',\n",
       " 'msg',\n",
       " 'msgs',\n",
       " 'mths',\n",
       " 'mu',\n",
       " 'much',\n",
       " 'mum',\n",
       " 'music',\n",
       " 'must',\n",
       " 'muz',\n",
       " 'na',\n",
       " 'name',\n",
       " 'nd',\n",
       " 'need',\n",
       " 'network',\n",
       " 'neva',\n",
       " 'never',\n",
       " 'new',\n",
       " 'news',\n",
       " 'next',\n",
       " 'ni',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'nite',\n",
       " 'noe',\n",
       " 'nokia',\n",
       " 'nope',\n",
       " 'nothing',\n",
       " 'nt',\n",
       " 'number',\n",
       " 'nyt',\n",
       " 'offer',\n",
       " 'office',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'okie',\n",
       " 'old',\n",
       " 'one',\n",
       " 'online',\n",
       " 'oops',\n",
       " 'open',\n",
       " 'operator',\n",
       " 'opt',\n",
       " 'orange',\n",
       " 'order',\n",
       " 'oredi',\n",
       " 'oso',\n",
       " 'pa',\n",
       " 'pain',\n",
       " 'park',\n",
       " 'part',\n",
       " 'party',\n",
       " 'pass',\n",
       " 'pay',\n",
       " 'people',\n",
       " 'per',\n",
       " 'person',\n",
       " 'phone',\n",
       " 'pic',\n",
       " 'pick',\n",
       " 'pics',\n",
       " 'place',\n",
       " 'plan',\n",
       " 'play',\n",
       " 'player',\n",
       " 'please',\n",
       " 'pls',\n",
       " 'plus',\n",
       " 'plz',\n",
       " 'pm',\n",
       " 'pmin',\n",
       " 'pmsg',\n",
       " 'po',\n",
       " 'pobox',\n",
       " 'point',\n",
       " 'poly',\n",
       " 'post',\n",
       " 'pound',\n",
       " 'ppm',\n",
       " 'press',\n",
       " 'pretty',\n",
       " 'price',\n",
       " 'princess',\n",
       " 'private',\n",
       " 'prize',\n",
       " 'prob',\n",
       " 'probably',\n",
       " 'problem',\n",
       " 'project',\n",
       " 'promise',\n",
       " 'pub',\n",
       " 'put',\n",
       " 'question',\n",
       " 'quite',\n",
       " 'quiz',\n",
       " 'rain',\n",
       " 'rate',\n",
       " 'reach',\n",
       " 'read',\n",
       " 'ready',\n",
       " 'real',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'receive',\n",
       " 'remember',\n",
       " 'reply',\n",
       " 'representative',\n",
       " 'request',\n",
       " 'return',\n",
       " 'reveal',\n",
       " 'reward',\n",
       " 'right',\n",
       " 'ring',\n",
       " 'ringtone',\n",
       " 'rite',\n",
       " 'room',\n",
       " 'rply',\n",
       " 'run',\n",
       " 'sad',\n",
       " 'sae',\n",
       " 'safe',\n",
       " 'saturday',\n",
       " 'save',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'sch',\n",
       " 'school',\n",
       " 'scream',\n",
       " 'sea',\n",
       " 'search',\n",
       " 'second',\n",
       " 'secret',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'select',\n",
       " 'sell',\n",
       " 'send',\n",
       " 'service',\n",
       " 'set',\n",
       " 'sex',\n",
       " 'sexy',\n",
       " 'shall',\n",
       " 'shit',\n",
       " 'shop',\n",
       " 'show',\n",
       " 'shower',\n",
       " 'simple',\n",
       " 'since',\n",
       " 'sir',\n",
       " 'sis',\n",
       " 'sister',\n",
       " 'sit',\n",
       " 'sleep',\n",
       " 'smile',\n",
       " 'smoke',\n",
       " 'sms',\n",
       " 'smth',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'sort',\n",
       " 'sound',\n",
       " 'speak',\n",
       " 'special',\n",
       " 'spend',\n",
       " 'st',\n",
       " 'stand',\n",
       " 'start',\n",
       " 'statement',\n",
       " 'stay',\n",
       " 'still',\n",
       " 'stop',\n",
       " 'story',\n",
       " 'study',\n",
       " 'stuff',\n",
       " 'sun',\n",
       " 'support',\n",
       " 'suppose',\n",
       " 'sure',\n",
       " 'surprise',\n",
       " 'sweet',\n",
       " 'ta',\n",
       " 'take',\n",
       " 'talk',\n",
       " 'tel',\n",
       " 'tell',\n",
       " 'ten',\n",
       " 'test',\n",
       " 'text',\n",
       " 'texts',\n",
       " 'th',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thanx',\n",
       " 'thats',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'thk',\n",
       " 'tho',\n",
       " 'though',\n",
       " 'til',\n",
       " 'till',\n",
       " 'time',\n",
       " 'tire',\n",
       " 'tmr',\n",
       " 'today',\n",
       " 'todays',\n",
       " 'together',\n",
       " 'tomo',\n",
       " 'tomorrow',\n",
       " 'tone',\n",
       " 'tonight',\n",
       " 'top',\n",
       " 'tot',\n",
       " 'touch',\n",
       " 'town',\n",
       " 'train',\n",
       " 'treat',\n",
       " 'trip',\n",
       " 'true',\n",
       " 'try',\n",
       " 'ts',\n",
       " 'turn',\n",
       " 'tv',\n",
       " 'two',\n",
       " 'txt',\n",
       " 'txting',\n",
       " 'txts',\n",
       " 'type',\n",
       " 'ugh',\n",
       " 'uk',\n",
       " 'uncle',\n",
       " 'understand',\n",
       " 'unlimited',\n",
       " 'unredeemed',\n",
       " 'unsubscribe',\n",
       " 'update',\n",
       " 'ur',\n",
       " 'urgent',\n",
       " 'us',\n",
       " 'use',\n",
       " 'valid',\n",
       " 'value',\n",
       " 'video',\n",
       " 'visit',\n",
       " 'voucher',\n",
       " 'vouchers',\n",
       " 'wait',\n",
       " 'wake',\n",
       " 'walk',\n",
       " 'wan',\n",
       " 'want',\n",
       " 'wat',\n",
       " 'watch',\n",
       " 'water',\n",
       " 'way',\n",
       " 'week',\n",
       " 'weekend',\n",
       " 'weekly',\n",
       " 'weeks',\n",
       " 'welcome',\n",
       " 'well',\n",
       " 'wen',\n",
       " 'whatever',\n",
       " 'whats',\n",
       " 'whole',\n",
       " 'wid',\n",
       " 'wif',\n",
       " 'wife',\n",
       " 'wil',\n",
       " 'win',\n",
       " 'wine',\n",
       " 'winner',\n",
       " 'wish',\n",
       " 'within',\n",
       " 'without',\n",
       " 'wk',\n",
       " 'wkly',\n",
       " 'wo',\n",
       " 'wonder',\n",
       " 'wonderful',\n",
       " 'wont',\n",
       " 'word',\n",
       " 'work',\n",
       " 'world',\n",
       " 'worry',\n",
       " 'worth',\n",
       " 'wot',\n",
       " 'would',\n",
       " 'write',\n",
       " 'wrong',\n",
       " 'xmas',\n",
       " 'xx',\n",
       " 'xxx',\n",
       " 'ya',\n",
       " 'yar',\n",
       " 'yeah',\n",
       " 'year',\n",
       " 'years',\n",
       " 'yes',\n",
       " 'yesterday',\n",
       " 'yet',\n",
       " 'yo',\n",
       " 'yr',\n",
       " 'yrs',\n",
       " 'yup']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "526e35aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_mat=pd.DataFrame(X_train_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c9493735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>abt</th>\n",
       "      <th>account</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>address</th>\n",
       "      <th>aft</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>age</th>\n",
       "      <th>ah</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.385692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.319641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4457 rows × 672 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      able  abt  account  actually       add  address  aft  afternoon  \\\n",
       "0      0.0  0.0      0.0       0.0  0.000000      0.0  0.0        0.0   \n",
       "1      0.0  0.0      0.0       0.0  0.000000      0.0  0.0        0.0   \n",
       "2      0.0  0.0      0.0       0.0  0.000000      0.0  0.0        0.0   \n",
       "3      0.0  0.0      0.0       0.0  0.385692      0.0  0.0        0.0   \n",
       "4      0.0  0.0      0.0       0.0  0.000000      0.0  0.0        0.0   \n",
       "...    ...  ...      ...       ...       ...      ...  ...        ...   \n",
       "4452   0.0  0.0      0.0       0.0  0.000000      0.0  0.0        0.0   \n",
       "4453   0.0  0.0      0.0       0.0  0.000000      0.0  0.0        0.0   \n",
       "4454   0.0  0.0      0.0       0.0  0.000000      0.0  0.0        0.0   \n",
       "4455   0.0  0.0      0.0       0.0  0.000000      0.0  0.0        0.0   \n",
       "4456   0.0  0.0      0.0       0.0  0.000000      0.0  0.0        0.0   \n",
       "\n",
       "           age   ah  ...  yeah      year  years  yes  yesterday  yet   yo  \\\n",
       "0     0.000000  0.0  ...   0.0  0.000000    0.0  0.0        0.0  0.0  0.0   \n",
       "1     0.000000  0.0  ...   0.0  0.000000    0.0  0.0        0.0  0.0  0.0   \n",
       "2     0.000000  0.0  ...   0.0  0.000000    0.0  0.0        0.0  0.0  0.0   \n",
       "3     0.000000  0.0  ...   0.0  0.325186    0.0  0.0        0.0  0.0  0.0   \n",
       "4     0.000000  0.0  ...   0.0  0.000000    0.0  0.0        0.0  0.0  0.0   \n",
       "...        ...  ...  ...   ...       ...    ...  ...        ...  ...  ...   \n",
       "4452  0.000000  0.0  ...   0.0  0.000000    0.0  0.0        0.0  0.0  0.0   \n",
       "4453  0.000000  0.0  ...   0.0  0.000000    0.0  0.0        0.0  0.0  0.0   \n",
       "4454  0.000000  0.0  ...   0.0  0.000000    0.0  0.0        0.0  0.0  0.0   \n",
       "4455  0.319641  0.0  ...   0.0  0.000000    0.0  0.0        0.0  0.0  0.0   \n",
       "4456  0.000000  0.0  ...   0.0  0.000000    0.0  0.0        0.0  0.0  0.0   \n",
       "\n",
       "       yr  yrs  yup  \n",
       "0     0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0  \n",
       "3     0.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0  \n",
       "...   ...  ...  ...  \n",
       "4452  0.0  0.0  0.0  \n",
       "4453  0.0  0.0  0.0  \n",
       "4454  0.0  0.0  0.0  \n",
       "4455  0.0  0.0  0.0  \n",
       "4456  0.0  0.0  0.0  \n",
       "\n",
       "[4457 rows x 672 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "40c21546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6b42bdbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a Naive Bayes model using X_train_dtm\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "nb = MultinomialNB()\n",
    "#nb = GaussianNB()\n",
    "nb.fit(doc_term_mat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9736d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "14ab779d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaura\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MultinomialNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class_train = nb.predict(doc_term_mat)\n",
    "y_pred_class = nb.predict(X_test_dtm.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "45344abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9757847533632287\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5acb9a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### as we can see the little accuracy has been incrased after using the Lemmatization in this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6ddd702d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[968   0]\n",
      " [ 27 120]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a53c9d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3857\n",
      "           1       0.97      0.85      0.91       600\n",
      "\n",
      "    accuracy                           0.98      4457\n",
      "   macro avg       0.98      0.92      0.95      4457\n",
      "weighted avg       0.98      0.98      0.98      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, y_pred_class_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "da3b4c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       968\n",
      "           1       1.00      0.82      0.90       147\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.91      0.94      1115\n",
      "weighted avg       0.98      0.98      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9cd55348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Now we will perform the Same steps with using the stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "85c0dda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms = pd.read_csv('D:/Python/Dataset/sms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "435a72cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2f2b0",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "47f70e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "def stemmer(x):\n",
    "    stemmer = PorterStemmer()\n",
    "    return ''.join([stemmer.stem(x) for x in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cc6cc397",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms['message']=sms['message'].apply(stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ba9928df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms['label']=sms['label'].map({'ham':0,'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f78a3c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=sms['message']\n",
    "y=sms['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8771d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8476d41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1642    hi , where are you? we're at  and they're not ...\n",
       "2899          if you r @ home then come down within 5 min\n",
       "480     when're you guys getting back? g said you were...\n",
       "3485    tell my  bad character which u dnt lik in me. ...\n",
       "157                           i'm leaving my house now...\n",
       "                              ...                        \n",
       "905     we're all getting worried over here, derek and...\n",
       "5192    oh oh... den muz change plan liao... go back h...\n",
       "3980    ceri u rebel! sweet dreamz me little buddy!! c...\n",
       "235     text & meet someone sexy today. u can find a d...\n",
       "5157                              k k:) sms chat with me.\n",
       "Name: message, Length: 4457, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8ff1731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_text(x):\n",
    "    x = x.lower()\n",
    "    x = x.strip()\n",
    "    x = re.sub(r' +', ' ', x)\n",
    "    x= re.sub(r\"[-()\\\"#/@;:{}`+=~|.!?,'0-9]\", \"\", x)\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f7bf5668",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(analyzer='word',lowercase=True, preprocessor=pre_process_text, ngram_range=(1,1), max_features=1000, max_df=0.95, min_df=10, stop_words=stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b70fc7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaura\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['arent', 'couldnt', 'didnt', 'doesnt', 'dont', 'hadnt', 'hasnt', 'havent', 'isnt', 'mightnt', 'mustnt', 'neednt', 'shant', 'shes', 'shouldnt', 'shouldve', 'thatll', 'wasnt', 'werent', 'wont', 'wouldnt', 'youd', 'youll', 'youre', 'youve'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4457x705 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 23266 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn training data vocabulary, then create document-term matrix\n",
    "vect = vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "70b6a52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a97da7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able',\n",
       " 'abt',\n",
       " 'account',\n",
       " 'actually',\n",
       " 'address',\n",
       " 'aft',\n",
       " 'afternoon',\n",
       " 'age',\n",
       " 'ah',\n",
       " 'aight',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'always',\n",
       " 'amp',\n",
       " 'ampm',\n",
       " 'angry',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'apply',\n",
       " 'ard',\n",
       " 'around',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'ass',\n",
       " 'attempt',\n",
       " 'auction',\n",
       " 'available',\n",
       " 'await',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'babe',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'beautiful',\n",
       " 'bed',\n",
       " 'believe',\n",
       " 'best',\n",
       " 'better',\n",
       " 'big',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bonus',\n",
       " 'book',\n",
       " 'bored',\n",
       " 'bout',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boytoy',\n",
       " 'break',\n",
       " 'bring',\n",
       " 'brother',\n",
       " 'bt',\n",
       " 'bus',\n",
       " 'busy',\n",
       " 'buy',\n",
       " 'call',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calls',\n",
       " 'camcorder',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'cant',\n",
       " 'car',\n",
       " 'card',\n",
       " 'care',\n",
       " 'carlos',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cause',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'charge',\n",
       " 'chat',\n",
       " 'check',\n",
       " 'chikku',\n",
       " 'choose',\n",
       " 'claim',\n",
       " 'class',\n",
       " 'close',\n",
       " 'club',\n",
       " 'code',\n",
       " 'collect',\n",
       " 'collection',\n",
       " 'college',\n",
       " 'colour',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comin',\n",
       " 'coming',\n",
       " 'company',\n",
       " 'complimentary',\n",
       " 'computer',\n",
       " 'confirm',\n",
       " 'congrats',\n",
       " 'congratulations',\n",
       " 'contact',\n",
       " 'cool',\n",
       " 'correct',\n",
       " 'cos',\n",
       " 'cost',\n",
       " 'could',\n",
       " 'course',\n",
       " 'coz',\n",
       " 'credit',\n",
       " 'cs',\n",
       " 'cum',\n",
       " 'customer',\n",
       " 'da',\n",
       " 'dad',\n",
       " 'darlin',\n",
       " 'dat',\n",
       " 'date',\n",
       " 'dating',\n",
       " 'day',\n",
       " 'days',\n",
       " 'de',\n",
       " 'dear',\n",
       " 'decided',\n",
       " 'delivery',\n",
       " 'den',\n",
       " 'details',\n",
       " 'didnt',\n",
       " 'die',\n",
       " 'difficult',\n",
       " 'dinner',\n",
       " 'dis',\n",
       " 'doesnt',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'double',\n",
       " 'download',\n",
       " 'draw',\n",
       " 'drink',\n",
       " 'drive',\n",
       " 'driving',\n",
       " 'drop',\n",
       " 'dude',\n",
       " 'dun',\n",
       " 'dunno',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'either',\n",
       " 'else',\n",
       " 'email',\n",
       " 'end',\n",
       " 'ends',\n",
       " 'enjoy',\n",
       " 'enough',\n",
       " 'enter',\n",
       " 'entry',\n",
       " 'eve',\n",
       " 'even',\n",
       " 'evening',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'expires',\n",
       " 'extra',\n",
       " 'face',\n",
       " 'family',\n",
       " 'far',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'film',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'finish',\n",
       " 'finished',\n",
       " 'first',\n",
       " 'fone',\n",
       " 'food',\n",
       " 'forever',\n",
       " 'forget',\n",
       " 'forgot',\n",
       " 'found',\n",
       " 'fr',\n",
       " 'free',\n",
       " 'freemsg',\n",
       " 'fri',\n",
       " 'friday',\n",
       " 'friend',\n",
       " 'friends',\n",
       " 'friendship',\n",
       " 'frnd',\n",
       " 'frnds',\n",
       " 'fuck',\n",
       " 'fucking',\n",
       " 'full',\n",
       " 'fun',\n",
       " 'game',\n",
       " 'games',\n",
       " 'gas',\n",
       " 'gd',\n",
       " 'get',\n",
       " 'getting',\n",
       " 'gift',\n",
       " 'girl',\n",
       " 'girls',\n",
       " 'give',\n",
       " 'go',\n",
       " 'god',\n",
       " 'goes',\n",
       " 'goin',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'gonna',\n",
       " 'good',\n",
       " 'goodmorning',\n",
       " 'got',\n",
       " 'gotta',\n",
       " 'gr',\n",
       " 'great',\n",
       " 'grins',\n",
       " 'gt',\n",
       " 'guaranteed',\n",
       " 'gud',\n",
       " 'guess',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'haf',\n",
       " 'haha',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'happiness',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'hav',\n",
       " 'havent',\n",
       " 'head',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'heart',\n",
       " 'hee',\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hes',\n",
       " 'hey',\n",
       " 'hi',\n",
       " 'hit',\n",
       " 'hold',\n",
       " 'holiday',\n",
       " 'home',\n",
       " 'hope',\n",
       " 'hot',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'hows',\n",
       " 'hrs',\n",
       " 'huh',\n",
       " 'hungry',\n",
       " 'hurt',\n",
       " 'id',\n",
       " 'identifier',\n",
       " 'ill',\n",
       " 'im',\n",
       " 'important',\n",
       " 'india',\n",
       " 'info',\n",
       " 'information',\n",
       " 'ipod',\n",
       " 'isnt',\n",
       " 'ive',\n",
       " 'job',\n",
       " 'join',\n",
       " 'jus',\n",
       " 'juz',\n",
       " 'keep',\n",
       " 'kind',\n",
       " 'kiss',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'knw',\n",
       " 'land',\n",
       " 'landline',\n",
       " 'laptop',\n",
       " 'lar',\n",
       " 'last',\n",
       " 'late',\n",
       " 'later',\n",
       " 'latest',\n",
       " 'least',\n",
       " 'leave',\n",
       " 'leaves',\n",
       " 'leaving',\n",
       " 'left',\n",
       " 'leh',\n",
       " 'lei',\n",
       " 'lesson',\n",
       " 'let',\n",
       " 'lets',\n",
       " 'liao',\n",
       " 'life',\n",
       " 'light',\n",
       " 'like',\n",
       " 'line',\n",
       " 'listen',\n",
       " 'little',\n",
       " 'live',\n",
       " 'loads',\n",
       " 'log',\n",
       " 'lol',\n",
       " 'long',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'lor',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'lots',\n",
       " 'lovable',\n",
       " 'love',\n",
       " 'lovely',\n",
       " 'lt',\n",
       " 'ltd',\n",
       " 'ltdecimal',\n",
       " 'luck',\n",
       " 'lucky',\n",
       " 'lunch',\n",
       " 'luv',\n",
       " 'made',\n",
       " 'mah',\n",
       " 'mail',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'man',\n",
       " 'many',\n",
       " 'mate',\n",
       " 'mates',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'mean',\n",
       " 'means',\n",
       " 'meant',\n",
       " 'meet',\n",
       " 'meeting',\n",
       " 'message',\n",
       " 'messages',\n",
       " 'might',\n",
       " 'min',\n",
       " 'mind',\n",
       " 'mine',\n",
       " 'mins',\n",
       " 'minute',\n",
       " 'minutes',\n",
       " 'miss',\n",
       " 'missed',\n",
       " 'missing',\n",
       " 'mob',\n",
       " 'mobile',\n",
       " 'mobileupd',\n",
       " 'money',\n",
       " 'month',\n",
       " 'months',\n",
       " 'morning',\n",
       " 'motorola',\n",
       " 'movie',\n",
       " 'mrng',\n",
       " 'msg',\n",
       " 'mths',\n",
       " 'mu',\n",
       " 'much',\n",
       " 'mum',\n",
       " 'music',\n",
       " 'must',\n",
       " 'muz',\n",
       " 'name',\n",
       " 'nd',\n",
       " 'need',\n",
       " 'needs',\n",
       " 'network',\n",
       " 'neva',\n",
       " 'never',\n",
       " 'new',\n",
       " 'news',\n",
       " 'next',\n",
       " 'ni',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'nite',\n",
       " 'noe',\n",
       " 'nokia',\n",
       " 'nope',\n",
       " 'nothing',\n",
       " 'nt',\n",
       " 'number',\n",
       " 'numbers',\n",
       " 'nyt',\n",
       " 'offer',\n",
       " 'office',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'okie',\n",
       " 'old',\n",
       " 'one',\n",
       " 'online',\n",
       " 'oops',\n",
       " 'open',\n",
       " 'operator',\n",
       " 'opt',\n",
       " 'orange',\n",
       " 'order',\n",
       " 'oredi',\n",
       " 'oso',\n",
       " 'pa',\n",
       " 'pain',\n",
       " 'parents',\n",
       " 'part',\n",
       " 'party',\n",
       " 'pay',\n",
       " 'people',\n",
       " 'per',\n",
       " 'person',\n",
       " 'phone',\n",
       " 'phones',\n",
       " 'pic',\n",
       " 'pick',\n",
       " 'picking',\n",
       " 'pics',\n",
       " 'place',\n",
       " 'plan',\n",
       " 'play',\n",
       " 'player',\n",
       " 'please',\n",
       " 'pls',\n",
       " 'plus',\n",
       " 'plz',\n",
       " 'pm',\n",
       " 'pmin',\n",
       " 'pmsg',\n",
       " 'po',\n",
       " 'pobox',\n",
       " 'points',\n",
       " 'poly',\n",
       " 'post',\n",
       " 'pounds',\n",
       " 'ppm',\n",
       " 'press',\n",
       " 'pretty',\n",
       " 'price',\n",
       " 'princess',\n",
       " 'private',\n",
       " 'prize',\n",
       " 'prob',\n",
       " 'probably',\n",
       " 'problem',\n",
       " 'project',\n",
       " 'pub',\n",
       " 'put',\n",
       " 'question',\n",
       " 'questions',\n",
       " 'quite',\n",
       " 'quiz',\n",
       " 'rate',\n",
       " 'reach',\n",
       " 'read',\n",
       " 'reading',\n",
       " 'ready',\n",
       " 'real',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'receive',\n",
       " 'remember',\n",
       " 'reply',\n",
       " 'representative',\n",
       " 'right',\n",
       " 'ring',\n",
       " 'ringtone',\n",
       " 'rite',\n",
       " 'room',\n",
       " 'rply',\n",
       " 'run',\n",
       " 'sad',\n",
       " 'sae',\n",
       " 'safe',\n",
       " 'said',\n",
       " 'sat',\n",
       " 'saturday',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'sch',\n",
       " 'school',\n",
       " 'sea',\n",
       " 'search',\n",
       " 'second',\n",
       " 'secret',\n",
       " 'see',\n",
       " 'seeing',\n",
       " 'seen',\n",
       " 'selected',\n",
       " 'send',\n",
       " 'sent',\n",
       " 'service',\n",
       " 'services',\n",
       " 'set',\n",
       " 'sex',\n",
       " 'sexy',\n",
       " 'shall',\n",
       " 'shes',\n",
       " 'shit',\n",
       " 'shop',\n",
       " 'shopping',\n",
       " 'show',\n",
       " 'shows',\n",
       " 'since',\n",
       " 'sir',\n",
       " 'sis',\n",
       " 'sister',\n",
       " 'sleep',\n",
       " 'sleeping',\n",
       " 'smile',\n",
       " 'smiling',\n",
       " 'smoke',\n",
       " 'sms',\n",
       " 'smth',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'sounds',\n",
       " 'speak',\n",
       " 'special',\n",
       " 'st',\n",
       " 'start',\n",
       " 'started',\n",
       " 'statement',\n",
       " 'stay',\n",
       " 'still',\n",
       " 'stop',\n",
       " 'story',\n",
       " 'stuff',\n",
       " 'sun',\n",
       " 'supposed',\n",
       " 'sure',\n",
       " 'sweet',\n",
       " 'take',\n",
       " 'takes',\n",
       " 'taking',\n",
       " 'talk',\n",
       " 'talking',\n",
       " 'tel',\n",
       " 'tell',\n",
       " 'telling',\n",
       " 'ten',\n",
       " 'test',\n",
       " 'text',\n",
       " 'texts',\n",
       " 'th',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thanx',\n",
       " 'thats',\n",
       " 'theres',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'thinking',\n",
       " 'thinks',\n",
       " 'thk',\n",
       " 'tho',\n",
       " 'though',\n",
       " 'thought',\n",
       " 'til',\n",
       " 'till',\n",
       " 'time',\n",
       " 'times',\n",
       " 'tired',\n",
       " 'tmr',\n",
       " 'today',\n",
       " 'todays',\n",
       " 'together',\n",
       " 'told',\n",
       " 'tomo',\n",
       " 'tomorrow',\n",
       " 'tone',\n",
       " 'tones',\n",
       " 'tonight',\n",
       " 'took',\n",
       " 'top',\n",
       " 'tot',\n",
       " 'touch',\n",
       " 'town',\n",
       " 'treat',\n",
       " 'tried',\n",
       " 'trip',\n",
       " 'true',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'ts',\n",
       " 'tv',\n",
       " 'two',\n",
       " 'txt',\n",
       " 'txting',\n",
       " 'txts',\n",
       " 'type',\n",
       " 'ugh',\n",
       " 'uk',\n",
       " 'uncle',\n",
       " 'unlimited',\n",
       " 'unredeemed',\n",
       " 'unsubscribe',\n",
       " 'update',\n",
       " 'ur',\n",
       " 'urgent',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'valid',\n",
       " 'valued',\n",
       " 'video',\n",
       " 'visit',\n",
       " 'voucher',\n",
       " 'vouchers',\n",
       " 'wait',\n",
       " 'waiting',\n",
       " 'wake',\n",
       " 'walk',\n",
       " 'wan',\n",
       " 'wanna',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'wants',\n",
       " 'wasnt',\n",
       " 'wat',\n",
       " 'watch',\n",
       " 'watching',\n",
       " 'water',\n",
       " 'wats',\n",
       " 'way',\n",
       " 'week',\n",
       " 'weekend',\n",
       " 'weekly',\n",
       " 'weeks',\n",
       " 'welcome',\n",
       " 'well',\n",
       " 'wen',\n",
       " 'went',\n",
       " 'whatever',\n",
       " 'whats',\n",
       " 'whole',\n",
       " 'wid',\n",
       " 'wif',\n",
       " 'wife',\n",
       " 'wil',\n",
       " 'win',\n",
       " 'wine',\n",
       " 'winner',\n",
       " 'wish',\n",
       " 'within',\n",
       " 'without',\n",
       " 'wk',\n",
       " 'wkly',\n",
       " 'wonderful',\n",
       " 'wont',\n",
       " 'word',\n",
       " 'words',\n",
       " 'work',\n",
       " 'working',\n",
       " 'world',\n",
       " 'worry',\n",
       " 'worth',\n",
       " 'wot',\n",
       " 'would',\n",
       " 'wrong',\n",
       " 'xmas',\n",
       " 'xx',\n",
       " 'xxx',\n",
       " 'ya',\n",
       " 'yar',\n",
       " 'yeah',\n",
       " 'year',\n",
       " 'years',\n",
       " 'yes',\n",
       " 'yesterday',\n",
       " 'yet',\n",
       " 'yo',\n",
       " 'youll',\n",
       " 'youre',\n",
       " 'youve',\n",
       " 'yr',\n",
       " 'yrs',\n",
       " 'yup']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Feature Names\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "X_train_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "daebb426",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_mat=pd.DataFrame(X_train_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "17b977c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>abt</th>\n",
       "      <th>account</th>\n",
       "      <th>actually</th>\n",
       "      <th>address</th>\n",
       "      <th>aft</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>age</th>\n",
       "      <th>ah</th>\n",
       "      <th>aight</th>\n",
       "      <th>...</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>youll</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "      <th>yr</th>\n",
       "      <th>yrs</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.322759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4457 rows × 705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      able  abt  account  actually  address  aft  afternoon       age   ah  \\\n",
       "0      0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.000000  0.0   \n",
       "1      0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.000000  0.0   \n",
       "2      0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.000000  0.0   \n",
       "3      0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.000000  0.0   \n",
       "4      0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.000000  0.0   \n",
       "...    ...  ...      ...       ...      ...  ...        ...       ...  ...   \n",
       "4452   0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.000000  0.0   \n",
       "4453   0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.000000  0.0   \n",
       "4454   0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.000000  0.0   \n",
       "4455   0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.322759  0.0   \n",
       "4456   0.0  0.0      0.0       0.0      0.0  0.0        0.0  0.000000  0.0   \n",
       "\n",
       "      aight  ...  yes  yesterday  yet   yo  youll  youre  youve   yr  yrs  yup  \n",
       "0       0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "1       0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "2       0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "3       0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "4       0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "...     ...  ...  ...        ...  ...  ...    ...    ...    ...  ...  ...  ...  \n",
       "4452    0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "4453    0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "4454    0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "4455    0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "4456    0.0  ...  0.0        0.0  0.0  0.0    0.0    0.0    0.0  0.0  0.0  0.0  \n",
       "\n",
       "[4457 rows x 705 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "90691d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a Naive Bayes model using X_train_dtm\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "nb = MultinomialNB()\n",
    "#nb = GaussianNB()\n",
    "nb.fit(doc_term_mat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "eececb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e0bc5cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gaura\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but MultinomialNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class_train = nb.predict(doc_term_mat)\n",
    "y_pred_class = nb.predict(X_test_dtm.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6a22d967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9748878923766816\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f137dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
